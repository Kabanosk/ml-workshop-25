{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd5978fa-4b79-4a1b-a496-827c973ecbce",
   "metadata": {},
   "source": [
    "# Zadanie 1: Perceptron - jak go zrobić porządnie?\n",
    "\n",
    "Podczas wykładu był pokazany kod do generowania perceptrona z dwoma wejściami. Spróbój napisać go dla `n` wejść - wagi możesz zainicjować za pomocą losowych wartości np. używając `np.random.randint`. Jeśli chcesz możesz spróbować to zrobić za pomocą mnożenia macierzy (*)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ace45959-0f71-447e-9e75-f4ad884c86b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random_array:\n",
      "[[3 2]\n",
      " [8 8]\n",
      " [8 4]]\n",
      "random_array.shape=(3, 2)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "random_array = np.random.randint(0, 10, (3,2)) # podajemy liczby od 0 do 9 oraz wymiary tablicy którą chcemy utworzyć \n",
    "print(f\"random_array:\\n{random_array}\")\n",
    "print(f\"{random_array.shape=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "894bfc0f-277a-4f59-bbb6-aa51b7265c9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01798620996209156"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "def activation_function(x):\n",
    "    return 1 / (1 + math.exp(-x))\n",
    "\n",
    "\n",
    "class Perceptron:\n",
    "    def __init__(self, w1=0.0, w2=0.0, b=0.0, activation_function=lambda x: x):\n",
    "        self.w = [w1, w2]  # wagi\n",
    "        self.b = b         # bias\n",
    "        self.act_fun = activation_function\n",
    "\n",
    "    def predict(self, x):\n",
    "        z = self.w[0] * x[0] + self.w[1] * x[1] + self.b\n",
    "        return self.act_fun(z)\n",
    "\n",
    "perceptron = Perceptron(2, 1, 2, activation_function)\n",
    "perceptron.predict(x=[-4,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6f709ea0-42a2-4eed-bcec-0762a1d72f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "\n",
    "def sigmoid(z):\n",
    "    return 1 / (1 + math.exp(-z))\n",
    "\n",
    "class Perceptron:\n",
    "    \"\"\"Perceptron dla n‑wymiarowego wejścia (tylko forward pass, bez macierzy).\"\"\"\n",
    "\n",
    "    def __init__(self, n_inputs, activation, weights=None, bias=None):\n",
    "        # TODO: Zapisz lub wygeneruj wagi\n",
    "        pass\n",
    "\n",
    "    def predict(self, x):\n",
    "        \"\"\"TODO: Policzyć sumę ważoną i zaaplikować funkcję aktywacji\"\"\"\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f807965b-ab6c-47bc-8a89-9dba559fdcef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perceptron tests passed!\n"
     ]
    }
   ],
   "source": [
    "def test_perceptron():\n",
    "    \"\"\"Sprawdza poprawność forward pass dla Perceptron.\"\"\"\n",
    "    perc = Perceptron(n_inputs=3, activation=sigmoid)\n",
    "    perc.w = [1, 1, 1]\n",
    "    perc.b = -2\n",
    "    assert perc.predict([1, 1, 1]) > 0.5, \"Should be classified as 1\"\n",
    "    assert perc.predict([0, 0, 0]) < 0.5, \"Should be classified as 0\"\n",
    "\n",
    "    print(\"Perceptron tests passed!\")\n",
    "\n",
    "# uruchom\n",
    "if __name__ == \"__main__\":\n",
    "    test_perceptron()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87eff8fe-61bf-4f35-882b-c7e6dd2f3fa5",
   "metadata": {},
   "source": [
    "# Zadanie 2: Zróbmy sobie MLP! 🚀\n",
    "\n",
    "Spróbuj znaleźć sposób do użycia klasy `Perceptron` do stworzenia działającego modelu **MLP (Multilayer Perceptron)** z jedną warstwą ukrytą."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "04371997-31ea-4de7-870f-b705bdd8e2e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable\n",
    "\n",
    "class SimpleMLP:\n",
    "    def __init__(self, input_dim: int, activation_function: Callable, hidden_units: int = 3):\n",
    "        # TODO: Warstwa ukryta: lista perceptronów przyjmujących n‑wymiarowy wektor\n",
    "\n",
    "        # TODO: Warstwa wyjściowa: perceptron przyjmujący hidden_units sygnałów\n",
    "        pass\n",
    "    def predict(self, x):\n",
    "        \"\"\"TODO: Funkcja predykcji dla x (lista liczb).\"\"\"\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b915b3c9-8eb8-410d-9db2-a34b5a20a13a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimpleMLP tests passed!\n"
     ]
    }
   ],
   "source": [
    "def test_simple_mlp():\n",
    "    mlp = SimpleMLP(input_dim=2, activation_function=sigmoid, hidden_units=2)\n",
    "\n",
    "    mlp.hidden[0].w = [20, 20]\n",
    "    mlp.hidden[0].b = -10\n",
    "\n",
    "    mlp.hidden[1].w = [-20, -20]\n",
    "    mlp.hidden[1].b = 30\n",
    "\n",
    "    mlp.out.w = [20, 20]\n",
    "    mlp.out.b = -30\n",
    "\n",
    "    assert mlp.predict([0, 0]) < 0.5\n",
    "    assert mlp.predict([1, 0]) > 0.5\n",
    "    assert mlp.predict([0, 1]) > 0.5\n",
    "    assert mlp.predict([1, 1]) < 0.5\n",
    "\n",
    "    print(\"SimpleMLP tests passed!\")\n",
    "\n",
    "test_simple_mlp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b7618b-fda3-44e3-9f2c-734c59cafad9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
