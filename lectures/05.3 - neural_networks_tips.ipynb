{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ðŸŽ¯ ULEPSZAMY NASZE MLP! â€” czyli jak nie zbudowaÄ‡ sieci, ktÃ³ra niczego siÄ™ nie nauczy\n",
        "\n",
        "## ðŸ” O co chodzi?\n",
        "\n",
        "W tej czÄ™Å›ci kursu zajmiemy siÄ™ **najczÄ™stszymi problemami**, jakie pojawiajÄ… siÄ™ przy trenowaniu prostych sieci neuronowych (MLP â€” Multi-Layer Perceptron). Nawet jeÅ›li Twoja sieÄ‡ dziaÅ‚a, to...\n",
        "\n",
        "> ...czy robi to **dobrze**?\n",
        "> Czy **uczy siÄ™ szybko**?\n",
        "> Czy nie **przeucza siÄ™**?\n",
        "> Czy naprawdÄ™ rozumiesz **co siÄ™ dzieje w Å›rodku**?\n",
        "\n",
        "---\n",
        "\n",
        "## ðŸš¨ Problemy, z ktÃ³rymi siÄ™ zmierzymy:\n",
        "\n",
        "- sieÄ‡ **uczy siÄ™ zbyt wolno**\n",
        "- **loss skacze** albo w ogÃ³le nie spada\n",
        "- model **zapamiÄ™tuje dane treningowe**, ale nie radzi sobie na nowych\n",
        "- wyniki **losowe jak totolotek**\n",
        "\n",
        "---\n",
        "\n",
        "## ðŸ§  Co dziÅ› dodamy do naszego kodu?\n",
        "\n",
        "KaÅ¼dy trick, ktÃ³ry dziÅ› zobaczysz, to **kilka linijek kodu**, ale moÅ¼e:\n",
        "- **zwiÄ™kszyÄ‡ dokÅ‚adnoÅ›Ä‡**\n",
        "- **przyspieszyÄ‡ naukÄ™**\n",
        "- **zmniejszyÄ‡ overfitting**\n",
        "- **poprawiÄ‡ stabilnoÅ›Ä‡** caÅ‚ego procesu\n",
        "\n",
        "Oto nasze â€žsupermoceâ€:\n",
        "\n",
        "| ðŸ› ï¸ Technika               | ðŸŽ¯ Co robi?                            |\n",
        "|--------------------------|----------------------------------------|\n",
        "| `Dropout`                | Gasi czÄ™Å›Ä‡ neuronÃ³w, by model nie \"oszukiwaÅ‚\" |\n",
        "| `Weight Decay`           | Kara za zbyt duÅ¼e wagi (regularizacja) |\n",
        "| `Learning Rate Decay`    | Zmniejsza krok ucznia w czasie         |\n",
        "| `Gradient Clipping`      | Powstrzymuje gradienty przed \"eksplozjÄ…\" |\n",
        "| `Early Stopping`         | KoÅ„czymy trenowanie w dobrym momencie |\n",
        "| `Data Augmentation`      | Sprawia, Å¼e dane sÄ… bardziej zrÃ³Å¼nicowane |\n",
        "\n",
        "---\n",
        "\n",
        "## ðŸ’¡ Cel\n",
        "\n",
        "> Chcemy zbudowaÄ‡ **prostÄ… sieÄ‡**, ale uczÄ…cÄ… siÄ™ **mÄ…drze**.  \n",
        "> ZrozumieÄ‡, **co siÄ™ psuje** â€” i jak to naprawiÄ‡.\n",
        "> Wykorzystamy do tego sieÄ‡, ktÃ³rÄ… zrobiliÅ›my na poprzednich Ä‡wiczeniach\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "zv4Y_Wd2g77V"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S4UuUceUg5Tw",
        "outputId": "5b97d9ed-37f3-42e5-f45b-c60d9a6654fe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "UÅ¼ywane urzÄ…dzenie: cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/5 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Batch 0] Loss: 2.3213\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|â–ˆâ–ˆ        | 1/5 [00:12<00:48, 12.10s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Batch 0] Loss: 0.1031\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:24<00:36, 12.09s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Batch 0] Loss: 0.2156\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:36<00:24, 12.05s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Batch 0] Loss: 0.0397\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:48<00:12, 12.04s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Batch 0] Loss: 0.2679\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [01:00<00:00, 12.03s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DokÅ‚adnoÅ›Ä‡ na zbiorze testowym: 96.13%\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "96.13"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "# ðŸ“¦ Import bibliotek\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "\n",
        "# ðŸ”§ Ustawienie urzÄ…dzenia\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"UÅ¼ywane urzÄ…dzenie: {device}\")\n",
        "\n",
        "# ðŸ“Š Ocena modelu na danych testowych\n",
        "def test_model(model, testloader):\n",
        "\n",
        "  correct = 0\n",
        "  total = 0\n",
        "\n",
        "  with torch.no_grad():\n",
        "      for inputs, labels in testloader:\n",
        "          inputs, labels = inputs.to(device), labels.to(device)\n",
        "          outputs = model(inputs)\n",
        "          _, predicted = torch.max(outputs.data, 1)\n",
        "          total += labels.size(0)\n",
        "          correct += (predicted == labels).sum().item()\n",
        "\n",
        "  print(f\"DokÅ‚adnoÅ›Ä‡ na zbiorze testowym: {100 * correct / total:.2f}%\")\n",
        "  return 100 * correct / total\n",
        "\n",
        "\n",
        "# ðŸ“¥ Wczytanie i przetwarzanie danych MNIST\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])\n",
        "\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "trainset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "\n",
        "testset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "\n",
        "# ðŸ§  Definicja sieci neuronowej przy uÅ¼yciu nn.Sequential\n",
        "model = nn.Sequential(\n",
        "    nn.Flatten(),                # SpÅ‚aszczenie obrazu 28x28 -> 784\n",
        "    nn.Linear(784, 128),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(128, 10)\n",
        ").to(device)\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "epochs = 5\n",
        "\n",
        "for epoch in tqdm(range(epochs)):\n",
        "    for batch_id, (inputs, labels) in enumerate(trainloader):\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = model(inputs)\n",
        "        loss = loss_fn(outputs, labels)\n",
        "\n",
        "\n",
        "        if batch_id % 1000 == 0:\n",
        "            print(f\"[Batch {batch_id}] Loss: {loss.mean():.4f}\")\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "test_model(model, testloader)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Dropout â€” czyli nie polegaj tylko na jednym neuronie\n",
        "\n",
        "Czasem sieÄ‡ za bardzo przywiÄ…zuje siÄ™ do konkretnych wag czy neuronÃ³w. Dropout losowo \"wyÅ‚Ä…cza\" czÄ™Å›Ä‡ z nich podczas treningu. DziÄ™ki temu sieÄ‡ uczy siÄ™ bardziej ogÃ³lnych cech i mniej siÄ™ przeucza.\n"
      ],
      "metadata": {
        "id": "WxcpxVeIlASI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_with_dropout = nn.Sequential(\n",
        "    nn.Flatten(),\n",
        "    nn.Linear(784, 128),\n",
        "    nn.ReLU(),\n",
        "    nn.Dropout(0.3),  # ðŸ‘ˆ dodajemy dropout 30%\n",
        "    nn.Linear(128, 10)\n",
        ").to(device)\n",
        "\n",
        "\n",
        "# dodajemy w optimizer weight_decay\n",
        "optimizer = optim.Adam(model_with_dropout.parameters(), lr=0.001)\n",
        "\n",
        "for epoch in tqdm(range(epochs)):\n",
        "    for batch_id, (inputs, labels) in enumerate(trainloader):\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = model_with_dropout(inputs)\n",
        "        loss = loss_fn(outputs, labels)\n",
        "\n",
        "\n",
        "        if batch_id % 1000 == 0:\n",
        "            print(f\"[Batch {batch_id}] Loss: {loss.mean():.4f}\")\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "\n",
        "test_model(model_with_dropout, testloader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "znKSeBIojXqt",
        "outputId": "a315dc5e-0197-451a-aed8-b0b7c843ffac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/5 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Batch 0] Loss: 2.3934\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|â–ˆâ–ˆ        | 1/5 [00:12<00:48, 12.20s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Batch 0] Loss: 0.2629\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:24<00:36, 12.06s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Batch 0] Loss: 0.2807\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:36<00:24, 12.02s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Batch 0] Loss: 0.1585\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:48<00:12, 12.03s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Batch 0] Loss: 0.2458\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [01:00<00:00, 12.03s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DokÅ‚adnoÅ›Ä‡ na zbiorze testowym: 94.19%\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "94.19"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Weight Decay (L2) â€” czyli mniej szalonych wag\n",
        "\n",
        "Zbyt duÅ¼e wagi = ryzyko, Å¼e model zapamiÄ™ta dane zamiast siÄ™ ich nauczyÄ‡. Weight Decay delikatnie karze duÅ¼e wagi i pomaga lepiej generalizowaÄ‡.\n"
      ],
      "metadata": {
        "id": "RLql3QidmImz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4) # ðŸ‘ˆ Nowa rzecz w optimizerze\n",
        "\n",
        "for epoch in tqdm(range(epochs)):\n",
        "    for batch_id, (inputs, labels) in enumerate(trainloader):\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = model(inputs)\n",
        "        loss = loss_fn(outputs, labels)\n",
        "\n",
        "\n",
        "        if batch_id % 1000 == 0:\n",
        "            print(f\"[Batch {batch_id}] Loss: {loss.mean():.4f}\")\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "\n",
        "test_model(model, testloader)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f6gs1rtImJSz",
        "outputId": "2046a91b-9af0-43d7-cea0-ad646b496bfa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/5 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Batch 0] Loss: 0.0654\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|â–ˆâ–ˆ        | 1/5 [00:12<00:48, 12.06s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Batch 0] Loss: 0.0652\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:24<00:36, 12.01s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Batch 0] Loss: 0.1097\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:36<00:24, 12.03s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Batch 0] Loss: 0.0895\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:48<00:12, 12.09s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Batch 0] Loss: 0.0202\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [01:00<00:00, 12.09s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DokÅ‚adnoÅ›Ä‡ na zbiorze testowym: 96.77%\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "96.77"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Learning Rate Decay â€” czyli zwalniamy przy finiszu\n",
        "\n",
        "Na poczÄ…tku warto robiÄ‡ duÅ¼e kroki (duÅ¼y learning rate), ale z czasem warto zwolniÄ‡, Å¼eby nie przegapiÄ‡ celu. Learning Rate Decay to strategia zmniejszania kroku w miarÄ™ postÄ™pu treningu.\n"
      ],
      "metadata": {
        "id": "-R65n8WimQEz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=2, gamma=0.5) # ðŸ‘ˆ NOWOÅšÄ†\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "for epoch in tqdm(range(epochs)):\n",
        "    for batch_id, (inputs, labels) in enumerate(trainloader):\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = model(inputs)\n",
        "        loss = loss_fn(outputs, labels)\n",
        "\n",
        "\n",
        "        if batch_id % 1000 == 0:\n",
        "            print(f\"[Batch {batch_id}] Loss: {loss.mean():.4f}\")\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    scheduler.step() # Po zakoÅ„czonym Batchu aktualizujemy nasz learning_rate\n",
        "\n",
        "\n",
        "test_model(model, testloader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uRVJg8zbmQgx",
        "outputId": "d8a9881b-af74-4720-82be-36c5bb58700c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/5 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Batch 0] Loss: 0.0625\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|â–ˆâ–ˆ        | 1/5 [00:12<00:49, 12.27s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Batch 0] Loss: 0.0440\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:24<00:36, 12.22s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Batch 0] Loss: 0.0668\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:36<00:24, 12.19s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Batch 0] Loss: 0.0336\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:48<00:12, 12.22s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Batch 0] Loss: 0.0495\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [01:01<00:00, 12.22s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DokÅ‚adnoÅ›Ä‡ na zbiorze testowym: 97.47%\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "97.47"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Gradient Clipping â€” czyli bez wybuchajÄ…cych gradientÃ³w\n",
        "Czasem gradienty mogÄ… osiÄ…gaÄ‡ absurdalnie wysokie wartoÅ›ci â€” szczegÃ³lnie na poczÄ…tku. To moÅ¼e sprawiÄ‡, Å¼e sieÄ‡ zamiast siÄ™ uczyÄ‡, bÄ™dzie tylko â€žkrzyczeÄ‡ w paniceâ€.\n",
        "\n",
        "Gradient Clipping to jak kaganiec â€” ogranicza dÅ‚ugoÅ›Ä‡ gradientÃ³w i pozwala trenowaÄ‡ stabilniej."
      ],
      "metadata": {
        "id": "YZOLiuENm2dI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in tqdm(range(epochs)):\n",
        "    for batch_id, (inputs, labels) in enumerate(trainloader):\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = model(inputs)\n",
        "        loss = loss_fn(outputs, labels)\n",
        "\n",
        "\n",
        "        if batch_id % 1000 == 0:\n",
        "            print(f\"[Batch {batch_id}] Loss: {loss.mean():.4f}\")\n",
        "\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0) # ðŸ‘ˆ To tutaj ustalamy maksymalny gradient\n",
        "        optimizer.step()\n",
        "\n",
        "\n",
        "test_model(model, testloader)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kjy2eM-Tm4W-",
        "outputId": "8f3ab87b-b938-4376-9ab1-4ada5db9129b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/5 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Batch 0] Loss: 0.1802\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|â–ˆâ–ˆ        | 1/5 [00:12<00:49, 12.47s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Batch 0] Loss: 0.0446\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:24<00:37, 12.43s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Batch 0] Loss: 0.0021\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:37<00:24, 12.40s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Batch 0] Loss: 0.0333\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:49<00:12, 12.31s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Batch 0] Loss: 0.0032\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [01:01<00:00, 12.31s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DokÅ‚adnoÅ›Ä‡ na zbiorze testowym: 97.54%\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "97.54"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Early Stopping â€” czyli wiesz kiedy przestaÄ‡\n",
        "Nie zawsze wiÄ™cej znaczy lepiej.\n",
        "Czasem sieÄ‡ zaczyna siÄ™ â€žpsuÄ‡â€ po kilku epokach, bo po prostu za dÅ‚ugo siÄ™ uczy.\n",
        "Wtedy dobrze mieÄ‡ Early Stopping â€” jeÅ›li dokÅ‚adnoÅ›Ä‡ nie poprawia siÄ™ przez kilka epok, po prostu przerywamy trening."
      ],
      "metadata": {
        "id": "AkHR_Qezm8wr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_acc = 1e8 # ðŸ‘ˆ zmienna do trzymania najlepszego lossu\n",
        "epochs_no_improve = 0 # ðŸ‘ˆ zmienna mÃ³wiÄ…ca ile epoch minÄ™Å‚o bez poprawy\n",
        "early_stop_patience = 3  # ðŸ‘ˆ zmienna mÃ³wiÄ…ca ile epoch tolerujemy (takich podczas ktÃ³rych moÅ¼e nie byÄ‡ poprawy)\n",
        "\n",
        "for epoch in tqdm(range(epochs)):\n",
        "    for batch_id, (inputs, labels) in enumerate(trainloader):\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = model(inputs)\n",
        "        loss = loss_fn(outputs, labels)\n",
        "\n",
        "\n",
        "        if batch_id % 1000 == 0:\n",
        "            print(f\"[Batch {batch_id}] Loss: {loss.mean():.4f}\")\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    if loss.item() < best_acc:  # ðŸ‘ˆ CaÅ‚a logika odnoÅ›nie Early Stoppingu\n",
        "        best_acc = loss.item()\n",
        "        epochs_no_improve = 0\n",
        "    else:\n",
        "        epochs_no_improve += 1\n",
        "\n",
        "    if epochs_no_improve >= early_stop_patience:\n",
        "        print(f\"Early stopping triggered after {epoch + 1} epochs.\")\n",
        "        break\n",
        "\n",
        "\n",
        "test_model(model, testloader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QnzZmO4_m-Dw",
        "outputId": "81eb372b-09c8-40cd-f40f-20a09e175180"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/5 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Batch 0] Loss: 0.0012\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|â–ˆâ–ˆ        | 1/5 [00:11<00:47, 11.95s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Batch 0] Loss: 0.0152\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:23<00:35, 11.88s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Batch 0] Loss: 0.0763\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:36<00:24, 12.22s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Batch 0] Loss: 0.0493\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:48<00:12, 12.15s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Batch 0] Loss: 0.0181\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [01:00<00:00, 12.12s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DokÅ‚adnoÅ›Ä‡ na zbiorze testowym: 97.34%\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "97.34"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Data Augmentation â€” czyli ucz siÄ™ na wiÄ™cej sposobÃ³w\n",
        "\n",
        "JeÅ›li pokazujesz modelowi tylko 1 wersjÄ™ danych, Å‚atwo je zapamiÄ™ta. Augmentacja (np. obracanie, szum, przesuniÄ™cia) tworzy sztucznie nowe przykÅ‚ady â€” sieÄ‡ uczy siÄ™ uogÃ³lniaÄ‡.\n"
      ],
      "metadata": {
        "id": "ldxXbTINmRKJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transform_aug = transforms.Compose([\n",
        "    transforms.RandomRotation(degrees=10),  # ðŸ‘ˆ Augmentacja\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])\n",
        "\n",
        "# ðŸ“¥ Wczytanie i przetwarzanie danych MNIST\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])\n",
        "\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "trainset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform_aug) # ðŸ‘ˆ Tutaj zmieniamy nasz transform w pobieraniu Datasetu\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "\n",
        "testset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "for epoch in tqdm(range(epochs)):\n",
        "    for batch_id, (inputs, labels) in enumerate(trainloader):\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = model(inputs)\n",
        "        loss = loss_fn(outputs, labels)\n",
        "\n",
        "\n",
        "        if batch_id % 1000 == 0:\n",
        "            print(f\"[Batch {batch_id}] Loss: {loss.mean():.4f}\")\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "\n",
        "test_model(model, testloader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eOhDJ7dNmS2S",
        "outputId": "d9458c8b-dce2-4041-86ff-59dbe77d8716"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/5 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Batch 0] Loss: 0.0500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|â–ˆâ–ˆ        | 1/5 [00:17<01:09, 17.40s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Batch 0] Loss: 0.0918\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:34<00:50, 16.97s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Batch 0] Loss: 0.0814\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:51<00:34, 17.08s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Batch 0] Loss: 0.0229\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [01:07<00:16, 16.90s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Batch 0] Loss: 0.0055\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [01:24<00:00, 16.90s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DokÅ‚adnoÅ›Ä‡ na zbiorze testowym: 97.50%\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "97.5"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Najlepsze na koniec!\n",
        "\n",
        "Czyli czy warto zawsze wszystkie z tych metod stosowaÄ‡ ze sobÄ…"
      ],
      "metadata": {
        "id": "NjWdEHkKov9C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transform_aug = transforms.Compose([\n",
        "    transforms.RandomRotation(degrees=10),  # ðŸ‘ˆ augmentacja\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])\n",
        "\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "trainset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform_aug)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "\n",
        "testset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "\n",
        "model = nn.Sequential(\n",
        "    nn.Flatten(),\n",
        "    nn.Linear(784, 128),\n",
        "    nn.ReLU(),\n",
        "    nn.Dropout(0.3),\n",
        "    nn.Linear(128, 10)\n",
        ").to(device)\n",
        "\n",
        "best_acc = 0\n",
        "epochs_no_improve = 0\n",
        "early_stop_patience = 3  # epoki bez poprawy\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=0.0001)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=2, gamma=0.5)\n",
        "\n",
        "for epoch in tqdm(range(epochs)):\n",
        "    for batch_id, (inputs, labels) in enumerate(trainloader):\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = model(inputs)\n",
        "        loss = loss_fn(outputs, labels)\n",
        "\n",
        "\n",
        "        if batch_id % 1000 == 0:\n",
        "            print(f\"[Batch {batch_id}] Loss: {loss.mean():.4f}\")\n",
        "\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "        optimizer.step()\n",
        "    scheduler.step()\n",
        "\n",
        "    if loss.mean() < best_acc:\n",
        "        best_acc = loss.mean()\n",
        "        epochs_no_improve = 0\n",
        "    else:\n",
        "        epochs_no_improve += 1\n",
        "\n",
        "    if epochs_no_improve >= early_stop_patience:\n",
        "        print(f\"Early stopping triggered after {epoch + 1} epochs.\")\n",
        "        break\n",
        "\n",
        "\n",
        "test_model(model, testloader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pfh_CchToxlv",
        "outputId": "2c499c93-5324-476f-ea18-7f025cbc7f30"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/5 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Batch 0] Loss: 2.3166\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|â–ˆâ–ˆ        | 1/5 [00:17<01:08, 17.10s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Batch 0] Loss: 0.2557\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:34<00:51, 17.10s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Batch 0] Loss: 0.2999\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:52<01:18, 26.01s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Early stopping triggered after 3 epochs.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DokÅ‚adnoÅ›Ä‡ na zbiorze testowym: 94.73%\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "94.73"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    }
  ]
}