{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 🎯 ULEPSZAMY NASZE MLP! — czyli jak nie zbudować sieci, która niczego się nie nauczy\n",
        "\n",
        "## 🔍 O co chodzi?\n",
        "\n",
        "W tej części kursu zajmiemy się **najczęstszymi problemami**, jakie pojawiają się przy trenowaniu prostych sieci neuronowych (MLP — Multi-Layer Perceptron). Nawet jeśli Twoja sieć działa, to...\n",
        "\n",
        "> ...czy robi to **dobrze**?\n",
        "> Czy **uczy się szybko**?\n",
        "> Czy nie **przeucza się**?\n",
        "> Czy naprawdę rozumiesz **co się dzieje w środku**?\n",
        "\n",
        "---\n",
        "\n",
        "## 🚨 Problemy, z którymi się zmierzymy:\n",
        "\n",
        "- sieć **uczy się zbyt wolno**\n",
        "- **loss skacze** albo w ogóle nie spada\n",
        "- model **zapamiętuje dane treningowe**, ale nie radzi sobie na nowych\n",
        "- wyniki **losowe jak totolotek**\n",
        "\n",
        "---\n",
        "\n",
        "## 🧠 Co dziś dodamy do naszego kodu?\n",
        "\n",
        "Każdy trick, który dziś zobaczysz, to **kilka linijek kodu**, ale może:\n",
        "- **zwiększyć dokładność**\n",
        "- **przyspieszyć naukę**\n",
        "- **zmniejszyć overfitting**\n",
        "- **poprawić stabilność** całego procesu\n",
        "\n",
        "Oto nasze „supermoce”:\n",
        "\n",
        "| 🛠️ Technika               | 🎯 Co robi?                            |\n",
        "|--------------------------|----------------------------------------|\n",
        "| `Dropout`                | Gasi część neuronów, by model nie \"oszukiwał\" |\n",
        "| `Weight Decay`           | Kara za zbyt duże wagi (regularizacja) |\n",
        "| `Learning Rate Decay`    | Zmniejsza krok ucznia w czasie         |\n",
        "| `Gradient Clipping`      | Powstrzymuje gradienty przed \"eksplozją\" |\n",
        "| `Early Stopping`         | Kończymy trenowanie w dobrym momencie |\n",
        "| `Data Augmentation`      | Sprawia, że dane są bardziej zróżnicowane |\n",
        "\n",
        "---\n",
        "\n",
        "## 💡 Cel\n",
        "\n",
        "> Chcemy zbudować **prostą sieć**, ale uczącą się **mądrze**.  \n",
        "> Zrozumieć, **co się psuje** — i jak to naprawić.\n",
        "> Wykorzystamy do tego sieć, którą zrobiliśmy na poprzednich ćwiczeniach\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "zv4Y_Wd2g77V"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S4UuUceUg5Tw",
        "outputId": "5b97d9ed-37f3-42e5-f45b-c60d9a6654fe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Używane urządzenie: cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/5 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Batch 0] Loss: 2.3213\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|██        | 1/5 [00:12<00:48, 12.10s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Batch 0] Loss: 0.1031\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|████      | 2/5 [00:24<00:36, 12.09s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Batch 0] Loss: 0.2156\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|██████    | 3/5 [00:36<00:24, 12.05s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Batch 0] Loss: 0.0397\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|████████  | 4/5 [00:48<00:12, 12.04s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Batch 0] Loss: 0.2679\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5/5 [01:00<00:00, 12.03s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dokładność na zbiorze testowym: 96.13%\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "96.13"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "# 📦 Import bibliotek\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "\n",
        "# 🔧 Ustawienie urządzenia\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Używane urządzenie: {device}\")\n",
        "\n",
        "# 📊 Ocena modelu na danych testowych\n",
        "def test_model(model, testloader):\n",
        "\n",
        "  correct = 0\n",
        "  total = 0\n",
        "\n",
        "  with torch.no_grad():\n",
        "      for inputs, labels in testloader:\n",
        "          inputs, labels = inputs.to(device), labels.to(device)\n",
        "          outputs = model(inputs)\n",
        "          _, predicted = torch.max(outputs.data, 1)\n",
        "          total += labels.size(0)\n",
        "          correct += (predicted == labels).sum().item()\n",
        "\n",
        "  print(f\"Dokładność na zbiorze testowym: {100 * correct / total:.2f}%\")\n",
        "  return 100 * correct / total\n",
        "\n",
        "\n",
        "# 📥 Wczytanie i przetwarzanie danych MNIST\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])\n",
        "\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "trainset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "\n",
        "testset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "\n",
        "# 🧠 Definicja sieci neuronowej przy użyciu nn.Sequential\n",
        "model = nn.Sequential(\n",
        "    nn.Flatten(),                # Spłaszczenie obrazu 28x28 -> 784\n",
        "    nn.Linear(784, 128),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(128, 10)\n",
        ").to(device)\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "epochs = 5\n",
        "\n",
        "for epoch in tqdm(range(epochs)):\n",
        "    for batch_id, (inputs, labels) in enumerate(trainloader):\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = model(inputs)\n",
        "        loss = loss_fn(outputs, labels)\n",
        "\n",
        "\n",
        "        if batch_id % 1000 == 0:\n",
        "            print(f\"[Batch {batch_id}] Loss: {loss.mean():.4f}\")\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "test_model(model, testloader)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Dropout — czyli nie polegaj tylko na jednym neuronie\n",
        "\n",
        "Czasem sieć za bardzo przywiązuje się do konkretnych wag czy neuronów. Dropout losowo \"wyłącza\" część z nich podczas treningu. Dzięki temu sieć uczy się bardziej ogólnych cech i mniej się przeucza.\n"
      ],
      "metadata": {
        "id": "WxcpxVeIlASI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_with_dropout = nn.Sequential(\n",
        "    nn.Flatten(),\n",
        "    nn.Linear(784, 128),\n",
        "    nn.ReLU(),\n",
        "    nn.Dropout(0.3),  # 👈 dodajemy dropout 30%\n",
        "    nn.Linear(128, 10)\n",
        ").to(device)\n",
        "\n",
        "\n",
        "# dodajemy w optimizer weight_decay\n",
        "optimizer = optim.Adam(model_with_dropout.parameters(), lr=0.001)\n",
        "\n",
        "for epoch in tqdm(range(epochs)):\n",
        "    for batch_id, (inputs, labels) in enumerate(trainloader):\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = model_with_dropout(inputs)\n",
        "        loss = loss_fn(outputs, labels)\n",
        "\n",
        "\n",
        "        if batch_id % 1000 == 0:\n",
        "            print(f\"[Batch {batch_id}] Loss: {loss.mean():.4f}\")\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "\n",
        "test_model(model_with_dropout, testloader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "znKSeBIojXqt",
        "outputId": "a315dc5e-0197-451a-aed8-b0b7c843ffac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/5 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Batch 0] Loss: 2.3934\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|██        | 1/5 [00:12<00:48, 12.20s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Batch 0] Loss: 0.2629\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|████      | 2/5 [00:24<00:36, 12.06s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Batch 0] Loss: 0.2807\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|██████    | 3/5 [00:36<00:24, 12.02s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Batch 0] Loss: 0.1585\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|████████  | 4/5 [00:48<00:12, 12.03s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Batch 0] Loss: 0.2458\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5/5 [01:00<00:00, 12.03s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dokładność na zbiorze testowym: 94.19%\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "94.19"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Weight Decay (L2) — czyli mniej szalonych wag\n",
        "\n",
        "Zbyt duże wagi = ryzyko, że model zapamięta dane zamiast się ich nauczyć. Weight Decay delikatnie karze duże wagi i pomaga lepiej generalizować.\n"
      ],
      "metadata": {
        "id": "RLql3QidmImz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4) # 👈 Nowa rzecz w optimizerze\n",
        "\n",
        "for epoch in tqdm(range(epochs)):\n",
        "    for batch_id, (inputs, labels) in enumerate(trainloader):\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = model(inputs)\n",
        "        loss = loss_fn(outputs, labels)\n",
        "\n",
        "\n",
        "        if batch_id % 1000 == 0:\n",
        "            print(f\"[Batch {batch_id}] Loss: {loss.mean():.4f}\")\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "\n",
        "test_model(model, testloader)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f6gs1rtImJSz",
        "outputId": "2046a91b-9af0-43d7-cea0-ad646b496bfa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/5 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Batch 0] Loss: 0.0654\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|██        | 1/5 [00:12<00:48, 12.06s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Batch 0] Loss: 0.0652\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|████      | 2/5 [00:24<00:36, 12.01s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Batch 0] Loss: 0.1097\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|██████    | 3/5 [00:36<00:24, 12.03s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Batch 0] Loss: 0.0895\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|████████  | 4/5 [00:48<00:12, 12.09s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Batch 0] Loss: 0.0202\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5/5 [01:00<00:00, 12.09s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dokładność na zbiorze testowym: 96.77%\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "96.77"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Learning Rate Decay — czyli zwalniamy przy finiszu\n",
        "\n",
        "Na początku warto robić duże kroki (duży learning rate), ale z czasem warto zwolnić, żeby nie przegapić celu. Learning Rate Decay to strategia zmniejszania kroku w miarę postępu treningu.\n"
      ],
      "metadata": {
        "id": "-R65n8WimQEz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=2, gamma=0.5) # 👈 NOWOŚĆ\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "for epoch in tqdm(range(epochs)):\n",
        "    for batch_id, (inputs, labels) in enumerate(trainloader):\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = model(inputs)\n",
        "        loss = loss_fn(outputs, labels)\n",
        "\n",
        "\n",
        "        if batch_id % 1000 == 0:\n",
        "            print(f\"[Batch {batch_id}] Loss: {loss.mean():.4f}\")\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    scheduler.step() # Po zakończonym Batchu aktualizujemy nasz learning_rate\n",
        "\n",
        "\n",
        "test_model(model, testloader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uRVJg8zbmQgx",
        "outputId": "d8a9881b-af74-4720-82be-36c5bb58700c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/5 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Batch 0] Loss: 0.0625\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|██        | 1/5 [00:12<00:49, 12.27s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Batch 0] Loss: 0.0440\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|████      | 2/5 [00:24<00:36, 12.22s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Batch 0] Loss: 0.0668\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|██████    | 3/5 [00:36<00:24, 12.19s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Batch 0] Loss: 0.0336\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|████████  | 4/5 [00:48<00:12, 12.22s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Batch 0] Loss: 0.0495\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5/5 [01:01<00:00, 12.22s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dokładność na zbiorze testowym: 97.47%\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "97.47"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Gradient Clipping — czyli bez wybuchających gradientów\n",
        "Czasem gradienty mogą osiągać absurdalnie wysokie wartości — szczególnie na początku. To może sprawić, że sieć zamiast się uczyć, będzie tylko „krzyczeć w panice”.\n",
        "\n",
        "Gradient Clipping to jak kaganiec — ogranicza długość gradientów i pozwala trenować stabilniej."
      ],
      "metadata": {
        "id": "YZOLiuENm2dI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in tqdm(range(epochs)):\n",
        "    for batch_id, (inputs, labels) in enumerate(trainloader):\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = model(inputs)\n",
        "        loss = loss_fn(outputs, labels)\n",
        "\n",
        "\n",
        "        if batch_id % 1000 == 0:\n",
        "            print(f\"[Batch {batch_id}] Loss: {loss.mean():.4f}\")\n",
        "\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0) # 👈 To tutaj ustalamy maksymalny gradient\n",
        "        optimizer.step()\n",
        "\n",
        "\n",
        "test_model(model, testloader)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kjy2eM-Tm4W-",
        "outputId": "8f3ab87b-b938-4376-9ab1-4ada5db9129b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/5 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Batch 0] Loss: 0.1802\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|██        | 1/5 [00:12<00:49, 12.47s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Batch 0] Loss: 0.0446\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|████      | 2/5 [00:24<00:37, 12.43s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Batch 0] Loss: 0.0021\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|██████    | 3/5 [00:37<00:24, 12.40s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Batch 0] Loss: 0.0333\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|████████  | 4/5 [00:49<00:12, 12.31s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Batch 0] Loss: 0.0032\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5/5 [01:01<00:00, 12.31s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dokładność na zbiorze testowym: 97.54%\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "97.54"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Early Stopping — czyli wiesz kiedy przestać\n",
        "Nie zawsze więcej znaczy lepiej.\n",
        "Czasem sieć zaczyna się „psuć” po kilku epokach, bo po prostu za długo się uczy.\n",
        "Wtedy dobrze mieć Early Stopping — jeśli dokładność nie poprawia się przez kilka epok, po prostu przerywamy trening."
      ],
      "metadata": {
        "id": "AkHR_Qezm8wr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_acc = 1e8 # 👈 zmienna do trzymania najlepszego lossu\n",
        "epochs_no_improve = 0 # 👈 zmienna mówiąca ile epoch minęło bez poprawy\n",
        "early_stop_patience = 3  # 👈 zmienna mówiąca ile epoch tolerujemy (takich podczas których może nie być poprawy)\n",
        "\n",
        "for epoch in tqdm(range(epochs)):\n",
        "    for batch_id, (inputs, labels) in enumerate(trainloader):\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = model(inputs)\n",
        "        loss = loss_fn(outputs, labels)\n",
        "\n",
        "\n",
        "        if batch_id % 1000 == 0:\n",
        "            print(f\"[Batch {batch_id}] Loss: {loss.mean():.4f}\")\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    if loss.item() < best_acc:  # 👈 Cała logika odnośnie Early Stoppingu\n",
        "        best_acc = loss.item()\n",
        "        epochs_no_improve = 0\n",
        "    else:\n",
        "        epochs_no_improve += 1\n",
        "\n",
        "    if epochs_no_improve >= early_stop_patience:\n",
        "        print(f\"Early stopping triggered after {epoch + 1} epochs.\")\n",
        "        break\n",
        "\n",
        "\n",
        "test_model(model, testloader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QnzZmO4_m-Dw",
        "outputId": "81eb372b-09c8-40cd-f40f-20a09e175180"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/5 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Batch 0] Loss: 0.0012\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|██        | 1/5 [00:11<00:47, 11.95s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Batch 0] Loss: 0.0152\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|████      | 2/5 [00:23<00:35, 11.88s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Batch 0] Loss: 0.0763\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|██████    | 3/5 [00:36<00:24, 12.22s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Batch 0] Loss: 0.0493\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|████████  | 4/5 [00:48<00:12, 12.15s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Batch 0] Loss: 0.0181\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5/5 [01:00<00:00, 12.12s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dokładność na zbiorze testowym: 97.34%\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "97.34"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Data Augmentation — czyli ucz się na więcej sposobów\n",
        "\n",
        "Jeśli pokazujesz modelowi tylko 1 wersję danych, łatwo je zapamięta. Augmentacja (np. obracanie, szum, przesunięcia) tworzy sztucznie nowe przykłady — sieć uczy się uogólniać.\n"
      ],
      "metadata": {
        "id": "ldxXbTINmRKJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transform_aug = transforms.Compose([\n",
        "    transforms.RandomRotation(degrees=10),  # 👈 Augmentacja\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])\n",
        "\n",
        "# 📥 Wczytanie i przetwarzanie danych MNIST\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])\n",
        "\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "trainset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform_aug) # 👈 Tutaj zmieniamy nasz transform w pobieraniu Datasetu\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "\n",
        "testset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "for epoch in tqdm(range(epochs)):\n",
        "    for batch_id, (inputs, labels) in enumerate(trainloader):\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = model(inputs)\n",
        "        loss = loss_fn(outputs, labels)\n",
        "\n",
        "\n",
        "        if batch_id % 1000 == 0:\n",
        "            print(f\"[Batch {batch_id}] Loss: {loss.mean():.4f}\")\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "\n",
        "test_model(model, testloader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eOhDJ7dNmS2S",
        "outputId": "d9458c8b-dce2-4041-86ff-59dbe77d8716"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/5 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Batch 0] Loss: 0.0500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|██        | 1/5 [00:17<01:09, 17.40s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Batch 0] Loss: 0.0918\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|████      | 2/5 [00:34<00:50, 16.97s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Batch 0] Loss: 0.0814\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|██████    | 3/5 [00:51<00:34, 17.08s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Batch 0] Loss: 0.0229\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|████████  | 4/5 [01:07<00:16, 16.90s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Batch 0] Loss: 0.0055\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5/5 [01:24<00:00, 16.90s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dokładność na zbiorze testowym: 97.50%\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "97.5"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Najlepsze na koniec!\n",
        "\n",
        "Czyli czy warto zawsze wszystkie z tych metod stosować ze sobą"
      ],
      "metadata": {
        "id": "NjWdEHkKov9C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transform_aug = transforms.Compose([\n",
        "    transforms.RandomRotation(degrees=10),  # 👈 augmentacja\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])\n",
        "\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "trainset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform_aug)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "\n",
        "testset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "\n",
        "model = nn.Sequential(\n",
        "    nn.Flatten(),\n",
        "    nn.Linear(784, 128),\n",
        "    nn.ReLU(),\n",
        "    nn.Dropout(0.3),\n",
        "    nn.Linear(128, 10)\n",
        ").to(device)\n",
        "\n",
        "best_acc = 0\n",
        "epochs_no_improve = 0\n",
        "early_stop_patience = 3  # epoki bez poprawy\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=0.0001)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=2, gamma=0.5)\n",
        "\n",
        "for epoch in tqdm(range(epochs)):\n",
        "    for batch_id, (inputs, labels) in enumerate(trainloader):\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = model(inputs)\n",
        "        loss = loss_fn(outputs, labels)\n",
        "\n",
        "\n",
        "        if batch_id % 1000 == 0:\n",
        "            print(f\"[Batch {batch_id}] Loss: {loss.mean():.4f}\")\n",
        "\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "        optimizer.step()\n",
        "    scheduler.step()\n",
        "\n",
        "    if loss.mean() < best_acc:\n",
        "        best_acc = loss.mean()\n",
        "        epochs_no_improve = 0\n",
        "    else:\n",
        "        epochs_no_improve += 1\n",
        "\n",
        "    if epochs_no_improve >= early_stop_patience:\n",
        "        print(f\"Early stopping triggered after {epoch + 1} epochs.\")\n",
        "        break\n",
        "\n",
        "\n",
        "test_model(model, testloader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pfh_CchToxlv",
        "outputId": "2c499c93-5324-476f-ea18-7f025cbc7f30"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/5 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Batch 0] Loss: 2.3166\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|██        | 1/5 [00:17<01:08, 17.10s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Batch 0] Loss: 0.2557\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|████      | 2/5 [00:34<00:51, 17.10s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Batch 0] Loss: 0.2999\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|████      | 2/5 [00:52<01:18, 26.01s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Early stopping triggered after 3 epochs.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dokładność na zbiorze testowym: 94.73%\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "94.73"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    }
  ]
}